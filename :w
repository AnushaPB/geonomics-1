#!/usr/bin/python
#genome.py


'''
##########################################

Module name:              genome

Module contents:          - definition of the Genome and Genomic_Architecture classes
                          - function for simulation of genomic architecture, simulation of a new genome, and associated functions


Author:                   Drew Ellison Hart
Email:                    drew.hart@berkeley.edu
Github:                   URL
Start date:               12-28-15
Documentation:            URL


##########################################
'''


import numpy as np    
from numpy import random as r
import random
import bitarray


######################################
# -----------------------------------#
# CLASSES ---------------------------#
# -----------------------------------#
######################################

class Trait:
    def __init__(self, idx, name, phi, n_loci, mu_nonneut, scape_num, alpha_dist_sigma, gamma, univ_advant):
        self.idx = idx
        self.name = name
        self.phi = phi
        self.n_loci = n_loci
        if mu_nonneut is None:
            mu_nonneut = 0
        self.mu_nonneut = mu_nonneut
        self.scape_num = scape_num
        self.alpha_dist_sigma = alpha_dist_sigma
        self.gamma = gamma
        self.univ_advant = univ_advant

        self.loci = np.array([])
        self.alpha = np.array([])


    def get_phi(self, pop):
        if type(self.phi) in (float, int):
            phi = np.array([self.phi]*len(pop))
        else:
            phi = self.phi[pop.cells[:,1], pop.cells[:,0]]
        return(phi)


class Recomb_Paths:
    def __init__(self, recomb_paths):
        self.recomb_paths = recomb_paths

    def get_paths(self, n):
        return(random.sample(self.recomb_paths, n))


class Genomic_Architecture:
    def __init__(self, p, h, r, g_params): 
        self.x = 2              #ploidy (NOTE: for now will be 2 by default; later could consider enabling polyploidy)
        self.L = g_params.L              #total length (i.e. number of markers)
        self.l_c = g_params.l_c          #length of each chromosome
        self.p = p              #Dict of allele frequencies for the 1-alleles for all (numbered by keys) chromosomes in haploid genome
        self.pleiotropy  = g_params.pleiotropy  #True/False regarding whether to allow a locus to affect the phenotype of more than one trait; defaults to False
        self.h = h          #Dict of heterozygous effects for all loci, for all chroms
        self.sex = g_params.sex
        self.r = r              #Dict of recombination rates between each locus and the next, for all chroms (NOTE: first will be forced to 1/float(x), to effect independent segregation of chroms, after which recomb occurs as a crossing-over path down the chroms
        self.recomb_lookup_array_size = g_params.recomb_lookup_array_size
        self.n_recomb_paths = g_params.n_recomb_paths

        self.recomb_paths = None  #The recombination-paths object will be assigned here; used to speed up large
                                #quantities of binomial draws needed for recombination

        #attributes for neutral loci
        self.mu_neut = g_params.mu_neut            #genome-wide neutral mutation rate  
        self.neut_loci = set(range(self.L))     #a set to keep track of all loci that don't influence the phenotypes of any trait; defaults to all loci, then will be updated
        self.nonneut_loci = set() #a set to keep track of all loci that influence the phenotype of at least one 
                                      #trait; after burn-in, will be updated

        #attributes for deleterious loci
        self.mu_delet = g_params.mu_delet                #genome-wide deleterious mutation rate
        self.delet_loci = set()
        self.mean_delet_alpha_dist = g_params.mean_delet_alpha_dist
        self.std_delet_alpha_dist = g_params.std_delet_alpha_dist
        
        #attribute for trait (i.e. adaptive) loci
        self.traits = make_traits(g_params.traits)
      
        #other attributes associated with mutation
            #a set to contain all mutable loci (i.e. loci where mutations can land)
        self.mutable_loci = set()    #a set containing eligible loci for mutation; after burn-in, will be updated
            #set self.mu_tot, the total per-site, per-generation mutation rate
        mus = [mu for mu in (self.mu_neut, self.mu_delet) if mu is not None]
        mus = mus + [trt.mu_nonneut for trt in self.traits.values()]
        self.mu_tot = sum(mus)
  

    #method for drawing an effect size for one or many loci 
    def draw_alpha(self, trait_num, n):
        alpha = r.normal(0, self.traits[trait_num].alpha_dist_sigma, n)
        if n == 1:
            alpha = np.abs(alpha)
        return(alpha)

    
    #method to draw mutation types for any number of mutations chosen to occur in a given timestep 
    def draw_mut_types(self, num):
        type_dict = {'neut': self.mu_neut,
                 'delet': self.mu_delet,
                **{'t%i' % (k):v.mu_nonneut for k,v in self.traits.items()} }
        types = []
        probs = []
        for k,v in type_dict.items():
            types.append(k)
            probs.append(v)
        probs = [p/sum(probs) for p in probs]
        choices = r.choice(types, p = probs, size = num, replace = True)
        return(choices)

   
    #method for assigning loci to traits 
    def set_trait_loci(self, trait_num, mutational=False, alpha=None, loci=None):

        #if this is not the result of a point mutation, but instead either an initial setup or manually
        #introduced, number of loci to be assigned
        if mutational == False:  
            n = self.traits[trait_num].n_loci
        else:
            n = 1

        #if locations provided manually, use those
        if loci != None:
            assert np.shape(loci) == 1, 'Object containing loci provided manually is not of dimension 1'
            loci = set([*loci])
        #otherwise draw loci randomly, either allowing pleiotropy or not
        elif not self.pleiotropy:
            loci = set(r.choice([*self.neutral], size = n, replace = False))
        elif self.pleiotropy:
            loci = set(r.choice(range(self.L), size = n, replace = False))

        #draw effects from a Gaussian dist with mean 0 and sigma provided by trait params (as per e.g.  Yeaman and Whitlock 2011)
        effects = self.draw_alpha(trait_num, n)

        #check that loci and effects are of equal length
        assert len(loci) == len(effects), 'Lengths of the two arrays containing the new trait loci and their effects are not equal.'

        #add these loci to the trait's 'loci' array
        self.traits[trait_num].loci = np.array([*self.traits[trait_num].loci] + list(loci))
        #and add their effects to the 'alpha' array
        self.traits[trait_num].alpha = np.array([*self.traits[trait_num].alpha] + list(effects))

        #add these loci to self.non-neutral and remove from self.neutral, to keep track of all loci underlying any traits (for purpose of avoiding pleiotropy)
        self.non_neutral.update(loci)
        self.neutral.difference_update(loci)


    #method for creating and assigning the r_lookup attribute
    def make_recomb_paths(self):
        self.recomb_paths = Recomb_Paths(make_recomb_paths_bitarrays(self))


    def show_freqs(self, pop):
        populome = np.hstack([ind.genome for ind in pop.values()])
        freqs = populome.sum(axis = 1)/(2*populome.shape[0])
        plt.plot(range(self.L), self.p, ':r')
        plt.plot(range(self.L), freqs, '_b')
        plt.show()


    #method for pickling a genomic architecture
    def write_pickle(self, filename):
        import cPickle
        with open(filename, 'wb') as f:
            cPickle.dump(self, f)


######################################
# -----------------------------------#
# FUNCTIONS -------------------------#
# -----------------------------------#
######################################

#generate allele_freqs
def draw_allele_freqs(l):
    return(r.beta(1,1,l))


#simulate genotypes
def draw_genotype(p): 
    return(r.binomial(1, p))


#randomly assign heterozygous effects, choosing from either 0, 0.5, or 1,
#where 0 = allele 1 (A1) dominant, 0.5 = codominant, 1 = A1 recessive, i.e.
#relative fitnesses: A1A1 = 1, A1A2 = 1-hs, A2A2 = 1-s
#NOTE: Should be able to also implement negative h values here, for overdominance
def draw_h(l, low = 0, high = 2):
    h  = r.randint(low = 0, high = 3, size = l)/2.   #NOTE: Pythonic style, so high is exclusive, hence high = 3
    return(h)


def make_traits(traits_params):
    params_copy = {**traits_params}
    #pop out the number of traits to create
    num_traits = len(params_copy)
    #then for each of i traits, unpack the ith components of the remaining params to create the trait dict
    traits = {k: Trait(k, **v) for k,v in params_copy.items()}
    return(traits)


#simulate linkage values
def draw_r(g_params, recomb_rate_fn = None):
    
    #use custom recomb_fn, if provided
    if recomb_rate_fn != None:
        recomb_array = np.array([max(0,min(0.5, recomb_rate_fn())) for locus in range(L)])
        return(recomb_array)

    #otherwise, use default function with either default or custom param vals
    else: 
        L = g_params.L

        param_vals = {'alpha_r': 7e2, 'beta_r': 7e3}

        for param in ['alpha_r', 'beta_r']:
            if (param in g_params.keys() and g_params[param] != None):
                param_vals[param] = g_params[param]
       
        recomb_array = np.array([max(0,min(0.5, recomb_rate)) for recomb_rate in r.beta(a = param_vals['alpha_r'], b = param_vals['beta_r'], size = L)])
    #NOTE: for now, using the Beta, which can be very flexibly parameterized
    #NOTE: current default alpha/beta vals, after being subtracted from 0.5 in sim_r function, will result in a tight distribution of r vals around 0.21 (~ 95% between 0.19 and 0.22)
    #NOTE: to essentially fix r at 0.5, Beta(1,1e7) will do...
    #NOTE: Ideally, would be good to look into to developing some sort of mixture distribution to reasonably and flexibly model map-distance values...

        return(recomb_array)


def get_chrom_breakpoints(l_c, L):

    breakpoints = np.array([0]+list(np.cumsum(sorted(l_c))[:-1]))

    assert np.alltrue(np.diff(np.array(list(breakpoints) + [L])) == np.array(sorted(l_c))), 'The breakpoints assigned will not produce chromosomes of the correct length'

    return(breakpoints)


#carry out recombination, using the lookup array in a Genomic_Architecture object
def make_recombinants(r_lookup, n_recombinants):
    recombinants = np.array([r.choice(r_lookup[i,], size = n_recombinants, replace = True) for i in range(len(r_lookup))])
    recombinants = np.cumsum(recombinants, axis = 0)%2
    return(recombinants)


def make_recomb_array(g_params):
    #get L (num of loci) and l_c (if provided; num of loci per chromsome) from the genome params dict
    L = g_params.L
    if ('l_c' in g_params.keys() and g_params['l_c'] != None and len(g_params['l_c']) > 1):
        l_c = g_params.l_c
        #and if l_c provided, check chrom lenghts sum to total number of loci
        assert sum(l_c) == L, 'The chromosome lengths provided do not sum to the number of loci provided.'
    else:
        l_c = [L]


    #if g_params.recomb_array (i.e a linkage map) manually provided (will break if not a list, tuple, or np.array), 
    #then set that as the recomb_array, and check that len(recomb_array) == L
    if ('recomb_array' in g_params.keys() and g_params['recomb_array'] != None):
        recomb_array = np.array(g_params.recomb_array)
        assert len(recomb_array) == L, "Length of recomb_array provided not equal to stipulated genome length ('L')."

        #NOTE: #Always necessary to set the first locus r = 1/ploidy, to ensure independent assortment of homologous chromosomes
        recomb_array[0] = 0.5
        #NOTE: for now, obligate diploidy
        #recomb_array[0] = 1/g_params.x 

        return(recomb_array, sorted(l_c))

    
    #otherwise, create recomb array
    else:

        #if a custom recomb_fn is provided, grab it
        if ('recomb_rate_custom_fn' in g_params.values() and g_params['recomb_rate_custom_fn'] is not None):
            recomb_rate_fn = g_params.recomb_rate_custom_fn
            assert callable(recomb_rate_fn), "The 'recomb_rate_custom_fn' provided in the parameters appears not to be defined properly as a callable function."
            #then call the draw_r() function for each locus, using custom recomb_fn
            recomb_array = draw_r(g_params, recomb_fn = recomb_rate_fn)



        #otherwise, use the default draw_r function to draw recomb rates
        else:
            recomb_array = draw_r(g_params) 


        #if more than one chromosome (i.e. if l_c provided in g_params dict and of length >1), 
        #set recomb rate at the appropriate chrom breakpoints to 0.5
        if len(l_c) >1:
            bps = get_chrom_breakpoints(l_c, L)
            recomb_array[bps] = 0.5


        #NOTE: #Always necessary to set the first locus r = 0.5, to ensure independent assortment of homologous chromosomes
        recomb_array[0] = 0.5
        #NOTE: for now, obligate diploidy
        #recomb_array[0] = 1/g_params.x


        return(recomb_array, sorted(l_c))


#function to create a lookup array, for raster recombination of larger numbers of loci on the fly
    #NOTE: size argument ultimately determines the minimum distance between probabilities (i.e. recombination rates)
    #that can be modeled this way
def make_recomb_paths_bitarrays(genomic_architecture, lookup_array_size = 10000, n_recomb_paths = 100000):
    
    if genomic_architecture.recomb_lookup_array_size is not None:
        lookup_array_size = genomic_architecture.recomb_lookup_array_size

    if genomic_architecture.n_recomb_paths is not None:
        n_recomb_paths = genomic_architecture.n_recomb_paths
    
    lookup_array = np.zeros((len(genomic_architecture.r),lookup_array_size), dtype = np.int8)

    for i, rate in enumerate(genomic_architecture.r):
        lookup_array[i,0:int(round(lookup_array_size*rate))] = 1

    recomb_paths = make_recombinants(lookup_array, n_recomb_paths).T
    bitarrays = tuple([make_bitarray_recomb_subsetter(p) for p in recomb_paths])
    
    return(bitarrays)


def make_bitarray_recomb_subsetter(recomb_path):
    ba = bitarray.bitarray(list(recomb_path.reshape((recomb_path.size,))))
    ba_inv = bitarray.bitarray(list(np.array(ba) == False))
    tot = []
    for i in range(len(ba)):
        tot.append(ba[i])
        tot.append(ba_inv[i])
    return(bitarray.bitarray(tot))


#build the genomic architecture
#NOTE: This will create the "template" for the genomic architecture that will then be used to simulate individuals and populations
def make_genomic_architecture(pop_params):

    #get the genome parameters
    g_params = pop_params.genome

    #also get the sex parameter and add it as an item in g_params
    g_params['sex'] = pop_params.mating.sex

    #draw locus-wise 1-allele frequencies
    p = draw_allele_freqs(g_params.L)  

    #draw locus-wise heterozygosity-effect values
        #TODO: THIS WHOLE FUNCTIONALITY NEEDS TO BE EITHER RETOOLED OR ELSE ERADICATED
    h = draw_h(g_params.L)

    
    r, l_c = make_recomb_array(g_params)
    #in case g_params.l_c was missing or None, because only a single chromosome is being simulated, then
    #replace g_params.l_c with the returned l_c value
    g_params.l_c = l_c

    #now make the gen_arch object
    gen_arch = Genomic_Architecture(p,h, r, g_params)

    #add the loci and effect sizes for each of the traits
    for trait_num in gen_arch.traits.keys():
        gen_arch.set_trait_loci(trait_num, mutational = False, loci = None)

    assert len(set(range(gen_arch.L)).difference(gen_arch.neutral.union(gen_arch.non_neutral))) == 0, 'ERROR: The union of the gen_arch.neutral and gen_arch.non_neutral sets does not contain all loci indicated by gen_arch.L'

    #create the r_lookup attribute
    gen_arch.make_recomb_paths()

    return(gen_arch)


#make genome
def draw_genome(genomic_architecture):
    new_genome = np.ones([genomic_architecture.L, genomic_architecture.x], dtype = np.int8)*9 #if for some reason any loci are not properly set to either 0 or 1, they will stick out as 9s
    for homologue in range(genomic_architecture.x):
        new_genome[:,homologue] = draw_genotype(genomic_architecture.p)

    assert type(new_genome) == np.ndarray, "A new genome must be an instance of numpy.ndarray"
    assert np.shape(new_genome) == (genomic_architecture.L, genomic_architecture.x), "A new genome must wind up with shape = (L, ploidy)."

    return(new_genome)


#function to reassign genomes after burn-in
def reset_genomes(pop, params):
    from ops import mutation

    #use mean n_births at tail end of burn-in to estimate number of mutations, and randomly choose set of neutral loci 
    #of that length to go into the pop.gen_arch.mutable attribute
    n_muts = mutation.calc_estimated_total_mutations(params, pop)
    #add 25, just a random small number, to be safe in case n_muts evals to 0
    n_muts += 25
    muts = set(r.choice([*pop.gen_arch.neutral], n_muts, replace = False))
    pop.gen_arch.mutables.update(muts)

    #set those loci's p values to 0 (i.e. non-segregating)
    pop.gen_arch.p[np.array([*muts])] = 0
    
    #now reassign genotypes to all individuals, using gen_arch.p
    [ind.set_genome(draw_genome(pop.gen_arch)) for ind in pop.values()]

       
#method for loading a pickled genomic architecture
def read_pickled_genomic_architecture(filename):
    import cPickle
    with open(filename, 'rb') as f:
        gen_arch = cPickle.load(f)

    return gen_arch

